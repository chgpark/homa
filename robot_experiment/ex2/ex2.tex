% -*- coding: utf-8 -*-
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{CJKutf8}

\newenvironment{Korean}{%
 \CJKfamily{mj}}{}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{mathtools}
\usepackage{listings, lstautogobble}
\usepackage{titlesec}
\usepackage{subcaption}
\usepackage{indentfirst}
\usepackage{makecell}

\begin{CJK}{UTF8}{}
\begin{Korean}

\title{Experiment 2, Occupancy grid map \& MCL}
\author{박창규}
\date{2019년 4월 12일}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\begin{document}
	\maketitle
	\thispagestyle{empty}
	\newpage
	\paragraph{Abstract}
	이번 실험에서는 mobile robot에 부착된 2D lidar sensor를 사용하여 얻은 range 데이터와 robot의 odometry를 데이터를 사용하여 occupancy grid map을 제작하고, Monte carlo localization(MCL) algorithm을 이용하여 생성한 robot의 potential location particle들 중 제작한 map과 2D lidar sensor data를 비교하여 높은 확률을 가지는 particle을 위주로 위치를 추정하여 robot의 location을 찾는 실험을 진행했습니다. 실험 과정에서 기준 점의 변경에 따른 데이터의 처리, 각 모듈 사이의 기하학적 위치의 반영 방법, occupancy grid map과 MCL에 대해 학습하였습니다.
	\tableofcontents
	\thispagestyle{empty}
	
	\newpage
	\setcounter{page}{1}
		
	\section{Introduction}
		\subsection{Robot mapping}
		Robot mapping은 robot navigation 중 한 부분으로 환경속에서 움직이는 robot이 해당 환경을 인식하기 위해서 환경을 공간정보에 기반하여 modeling 하고 시간에 따라 유지하는 것입니다. 환경의 인식의 한 예로 robot이 자신 혹은 환경 속에 존재하는 다른 물체의 위치추정과 장애물의 인식이 있습니다. Mapping을 통해서 robot은 outdoor 혹은 indoor 환경에서 자신의 위치를 알고 임무를 수행할 수 있습니다.\\
		\indent 환경의 인식은 두가지 종류의 정보를 통해 이루어집니다. 첫째는 스스로의 동작을 통해 얻을 수 있는 idiothetic 정보입니다. 예를 들어, 바퀴의 회전수를 측정하고 측정한 데이터를 dead reckoning하여 얻는 odometry와 같이 internal sensor를 통해 얻을 수 있는 정보입니다. 둘째는 robot 외부에 부착된 센서를 통해 얻는 allothetic 정보입니다. 예를 들어, 카메라, laser, lidar와 같은 external sensor들을 통해 얻는 정보입니다.\\
		\indent 위 두가지 정보를 활용하여 그림 2와 같이 mapping을 진행합니다. robot mapping의 진행 과정은 internal과 external sensor로부터 얻은 데이터를 통해 robot의 position을 갱신하고 map의 spatial model을 생성하는 것입니다.
		\subsection{Map generation \& localization}
		\indent 이 실험에서는 inertial measurement unit(IMU)와 encoder를 통해 얻은 데이터를 dead rekoning한 odometry와 2D lidar sensor를 통해 얻은 환경의 range measurment를 활용하여 robot mapping을 진행하였습니다.\\
		\indent Robot mapping은 map generation과 localization 두 부분으로 나누어서 진행하였습니다. 우선 map generation은 그림 3과 같습니다. Internal sensor data를 통해 position을 갱신하고 external sensor와 position 데이터를 통합하여 map의 spatial model을 만듭니다. 다음으로 localization은 그림 4와 같습니다. External sensor로부터 얻은 데이터와 map의 spatial model을 비교하여 robot의 location 정보를 추정하고 internal sensor를 통해 position 정보를 갱신하는 과정을 지속적으로 반복하며 map 상에서 로봇의 위치를 찾습니다.\\
		\indent 실험에서 사용한 map generation 방법은 Occupancy grid map이고, localization방법은 Monte carlo localization입니다.\\
		
		\begin{table}[h]
		\centering
		\caption{Map generation \& Localization method using in experiment}
		\begin{tabular}{c|c}
			\textbf{Process} & \textbf{Method}   \\
			\hline
			Map generation & Occupancy grid map\\
			\hline
			Localization & Monte carlo localization\\
		\end{tabular}
		\label{table:methods}
		\end{table}
		
		\subsection{Occupancy Grid Map}
		
		\subsection{Monte Carlo Localization}
		
	\section{Experiment}
		\subsection{Experimental system}


		\subsection{Code explanation}
		
			\subsubsection{Map generation part}
			\subsubsection{Localization part}
			
	\section{Result}
	
	\section{Conclusion}
	
	위키 robot navigation
\end{Korean}
\end{CJK}
\end{document}

